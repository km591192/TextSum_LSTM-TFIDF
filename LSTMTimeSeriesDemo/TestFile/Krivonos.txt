Данный электронный документ является научно исследовательской работой. 
В работе ставится цель исследования и модификация алгоритмов в задачах классификации и прогнозирования. 
В задачах классификации выбран алгоритм KNN. 
В качестве предметной области выступает выборка об уровне развития информационных технологий в странах мира. 
Результаты модификаций описывают качество реализованного алгоритма, также, для наглядности представлены графики результатов тестирования. В задачах прогнозирования выбран алгоритм SLIQ. 
В результате проведенного анализа строится теоретическое предположение о результатах модификаций данного алгоритма.
На данный момент, объемы информации накопленные человечеством достигают невероятно крупных размеров, и существует необходимость разнообразной обработки этих данных. 
Необходимость выявления разного рода зависимостей в больших объемах информации достаточно высока в связи с необходимостью улучшать существующие системы используя накопленные данные. 
Для выявления новых знаний и неочевидных зависимостей применяются разнообразные методы Data Mining. Рассмотрим задачи классификации и  прогнозирования. 
Существует определённое множество экземпляров.  
Каждый екземпляр относится к одному из возможных классов. 
Задано определенное множество экземпляров, заранее распределенных по классам. Это множество носит название «обучающая выборка». Оно служит для дальнейшего обучения алгоритма. 
Классы остальных экземпляров неизвестны. Задача - построить определенный алгоритм или метод, который сможет классифицировать любой экземпляр из начального множества.
Прогнозирование - установление функциональной зависимости между зависимыми и независимыми переменными. 
Прогнозирование направлено на определение тенденций динамики конкретного объекта или события на основе ретроспективных данных, т.е. анализа его состояния в прошлом и настоящем. 
Таким образом, решение задачи прогнозирования требует некоторой обучающей выборки данных. 
Задача прогнозирования подразумевает под собой выбор следующих компонент: метод прогнозирования; модель прогнозирования.
Метод прогнозирования представляет собой последовательность действий, которые нужно совершить для получения модели прогнозирования. 
Модель прогнозирования есть функциональное представление, адекватно описывающее исследуемый процесс и являющееся основой для получения его будущих значений.
Исходя из формального определения этих двух задач, они не выглядят очень схожими, однако решаются одними и теми же алгоритмами, различаясь при этом лишь способом применения данных алгоритмов.
Целью данной работы является исследование алгоритмов и возможных модификаций этих алгоритмов в задачах классификации и прогнозирования.  
Рассмотрим алгоритм метрической классификации «k ближайших соседей» для задачи классификации рейтинга стран. 
В качестве классов выступают следующие уровни развития: Высокий (High), Средний (Medium), Низкий (Low).
Основная идея метода заключается в присвоении новому объекту класса наиболее распространненного среди ближайших соседей данного элемента.
Соседи выбираются из множества, уже классифицированных тем или иным образом, объектов,  и, исходя из количественного значения k, высчитывается преобладание одного из классов среди соседей.
Каждый объект имеет конечное количество атрибутов (размерностей). Предполагается, что существует определенный набор объектов с уже имеющейся классификацией.
Далее рассмотрим задачу определения дистанции. Классический вариант определения дистанции - дистанция в евклидовом пространстве. 
При таком способе во внимание принимается не только количество попавших в область определенных классов, но и их удаленность от нового значения.
В исходном виде модель алгоритмов kNN крайне бедна. Она имеет только свободный параметр k, да и тот дискретный с небольшим числом разумных альтернатив. 
Для обогащения модели необходимо вводить веса объектов и/или параметризовать способ вычисления метрики.
В работе предлагается улучшить данный алгоритм путём проведения анализа и улучшения трёх его основных блоков. 
Этими блоками являются: блок обработки входных данных, блок метрик и блок выборщика. Опишем возможные изменения в каждом из данных блоков.
Первая фаза включает в себя нормализацию входных параметров. 
Реализовано два варианта нормализации. 
Первый вариант это стандартная нормализация – приведение всех параметров к промежутку [0,1], путем деления каждого входного параметра на максимальное значение соответствующего параметра среди всей выборки. 
Второй – минимаксная нормализация. Данный вариант нормализации описывается формулой.
Вторая фаза заключается в выборе весовых коэффициентов для параметров объектов выборки. Используется 2 метода: метод скользящего контроля; метод отжига.
В данном блоке решается задача выбора метрики. Стандартной для алгоритма KNN является Евклидова метрика. Однако существует ряд других метрик конкурирующих с данной.
Манхэттенская метрика или расстояние городских кварталов. По сравнению с евклидовым расстоянием влияние отдельных больших разностей (выбросов) уменьшается, так как они не возводятся в квадрат.
Расстояние Минковского (метрика Минковского) - параметрическая метрика на евклидовом пространстве, которую можно рассматривать как обобщение евклидова расстояния и расстояния городских кварталов.
Стандартный выборщик класса для контрольного объекта в алгоритме KNN пользуется принципом большинства. Модифицировать данный блок можно с помощью учёта расстояния до объектов. Название такого метода «взвешенное голосование».
Данный метод предполагает учет расстояния до нового экземпляра. Чем меньше расстояние от нового экземпляра до принимающего в голосовании участие элемента, тем более значимый голос этого элемента. 
Новому экземпляру будет присвоен класс, победивший в голосовании. 
При этом снижается вероятность набора одинакового количества голосов несколькими классами. Очевидно, что если k=1, то новый экземпляр по сути не проходит процесс голосования, а перенимает класс у ближайшего соседа.
Обучение алгоритма происходило на обучающей выборке. Целью обучения является отладка алгоритма и проверка его работоспособности с разными параметрами.
После отладки работы алгоритма, целью стал выбор наиболее подходящих коэффициентов и определение наиболее результативной метрики. 
Наилучшим – будем считать тот набор коэффициентов при котором k – наименьшее, а качество классификации наибольшее, т.е. если две разные метрики дали одинаковый результат классификации, но одна из них показала этот результат при меньшем k – то она считается лучшей. 
И по результатам данных тестов наилучшим образом себя показала Манхэттенская метрика, с коэффициентом k=5.
Из полученных данных следует, что на контрольной выборке введение модификаций приводит к улучшению качества и стабильности работы алгоритма при различных k. Максимальное качество классификации повысилось с 89% до 96%.
Минимальное качество классификации повысилось с 65% до 76%. Среднее значение качества классификации также повысилось с 74.6833% до 86.8%. 
Таким образом, влияние модификаций на изначальный алгоритм привело к улучшению качества работы алгоритма в  среднем на 10-12%. 
Задачи прогнозирования и задачи классификации решают методами машинного обучения, к которым относятся алгоритмы рассматриваемые в данной работе. 
Модификация алгоритма к-ближайших соседей  привело к улучшению результатов решения задачи классификации. 
Следовательно, можно предположить, что и алгоритмы используемые в задачах прогнозирования, могут быть модифицированы и улучшены.
В задачах прогнозирования рассмотрим алгоритмы построения дерева решений. 
Существует огромное количество методов, позволяющих создавать деревья решений. Основными считаются алгоритмы ID3, C4.5, CART, MARS. Для обработки больших данных был разработан и описан метод SLIQ.
Алгоритм SLIQ обладает следующей структурой:-предварительная сортировка данных;-построение дерева, ветвление;-отсечение ветвей.
На этапах построения дерева и отсечения ветвей возможен выбор в пользу тех или иных алгоритмов и методов, или их модификаций. Опишем каждый из этапов и возможные модификации к ним.
На данном этапе происходит разбиение изначальной таблицы данных обучающей выборки на компонующие её таблицы, состоящие ровно из двух столбцов, столбца атрибута и столбца индекса класса к которому он относится. 
При этом данные в этих компонующих таблицах должны быть отсортированы по возрастанию.  
В дополнение к этому строится таблица соответствий классов к листьям дерева, на начальном этапе все классы будут относиться к корню дерева, в последствии эта таблица будет модифицироваться для соответствия решающему дереву.
На этапе построения дерева существуют три проблемы решение которых определяет качество работы алгоритма, а именно: выбор атрибута, выбор значения разбиения и правило остановки.
В проблеме выбора атрибута не существует оптимального алгоритма или метода, который бы обеспечивал максимально оптимально построенное дерево за приемлемое время. 
Однако, были разработаны два критерия, оба из которых следуют правилу поиска локального оптимального решения в каждом узле, обеспечивая создание дерева за приемлемое время. 
Такими критериями являются статистический критерий  и теоретико-информационный критерий.
Критерий на основании статистики изначально использовался в алгоритме CART и носит название индекса Gini. Он создан для оценки фактического расстояния между группами классов.
Теоретико-информационный критерий используется в алгоритме C4.5 и создан для выбора наиболее успешного алгоритма.
Проблема выбора значения разбиения в классических задачах решается методом перебора всех возможных значений выбранного атрибута в узле дерева, после чего, по описанным выше критериям, определяется насколько удачным было такое разбиение и берётся следующее значение атрибута. 
В результате выбирается наиболее удачное разбиение.
В качестве модификации данного способа, предлагается использование случайных чисел для ускорения процесса нахождения максимально оптимального значения критериев в узле. 
Так же возможен вариант бинарного разделения множества возможных значений выбранного атрибута для поиска оптимального значения.
Правило остановки должно отвечать на вопрос о том стоит ли продолжать разбиение узла или завершить разбиение для данного узла. 
В качестве модификации основного метода предлагаются следующие вспомогательные правила.
Метод ранней остановки (preprunning). Данный метод основывается на статистических данных для выявления необходимости дальнейшего разбиения. 
Таким образом, достигается уменьшение времени обучения. Однако стоит заметить, что при использовании данного подхода получаются менее точные деревья, следовательно этот метод нежелательно использовать. 
Признанные авторитеты в этой области Брейман и Куинлен советуют буквально следующее: "Вместо остановки используйте отсечение".
Также можно ограничить глубину дерева. 
Под этим подразумевается остановка дальнейшего построения после превышения определенной глубины. 
Разбиение обязано быть нетривиальным. Это значит, что узлы, получившиеся в результате такого разбиения, должны группировать определенное количество экземпляров.
Каждое из данных правил является эвристическим. Следовательно, не существует такого, которое бы имело большую практическую ценность. 
Таким образом, стоит использовать то или иное правило в зависимости от контекста, то есть от конкретного частного случая. 
На этапе отсечения ветвей выполняется усечение дерева путём откидывания или замены ветвей на более компактные. 
Необходимость данного этапа заключена в эффекте переобучения. В результате этого эффекта получается слишком ветвистое дерево. 
Это дерево отлично классифицирует обучающую выборку, однако является слишком большим и непригодным для использования на новых данных. 
Основное правило, которым руководствуются методы отсечения, звучит следующим образом: «отсекать или заменять поддеревом ветвь, если это увеличит ошибку». 
Иногда, даже после процесса усечения, деревья могут быть слишком объемны и не информативны. 
Тогда, стоит использовать методику сбора метаданных из дерева извлекая наборы правил, описывающих представленные классы.
Метод, который извлекает правила, исследует все возможные пути из корня дерева до листа. 
Каждый проход сформирует правило, в котором условия будут формироваться из проверок внутри каждого узла на пути от корня до листа.
Учитывая проведённый анализ алгоритма KNN, результатом которого является общее улучшение классификации на 10-12%, предполагается, что введение модификаций в алгоритм SLIQ должно привести к подобным результатам.